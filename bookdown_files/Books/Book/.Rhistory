# 把所有符合某种标题的文件全部读取到一个list中
files <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$")
head(files, n = 10L)
str(files)
# 创建一个空的列表来存储读取的数据框
df_list <- list()
# 循环读取每个文件，处理数据并添加到列表中
for (i in seq_along(files)) { # 重复"读取到的.out个数"的次数
# 对每个.out，使用read.table
df <- read.table(file.path("data/match", files[i]), header = TRUE) #read.table似乎比read.csv更聪明，不需要指定分隔符
# 给读取到的每个.out文件的每个变量统一变量格式
df <- dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT))
# 将数据框添加到列表中
df_list[[i]] <- df
}
# 合并所有数据框，只有当变量的属性一致时，才可以bind_rows
# bind_rows 意味着把list中的所有表格整合成一个大表格
df.mt.out.fl <- dplyr::bind_rows(df_list)
# 清除中间变量
rm(df,df_list,files,i)
# 如果你将这个步骤写成函数，则这些变量自然不会出现在全局变量中
DT::datatable(head(df.mt.out.fl, 100),
fillContainer = TRUE, options = list(pageLength = 7))
data.table::datatable(head(df.mt.out.fl, 100),
fillContainer = TRUE, options = list(pageLength = 7))
datatable(head(df.mt.out.fl, 100),
fillContainer = TRUE, options = list(pageLength = 7))
install.packages("DT")
library(DT)
DT::datatable(head(df.mt.out.fl, 100),
fillContainer = TRUE, options = list(pageLength = 7))
# 获取所有的.out文件名
df.mt.out.la <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$") %>%
# 对读取到的所有.out文件x都执行函数read.table
lapply(df.mt.out.la,function(x) read.table(file.path("data/match", x), header = TRUE)) %>%
# 对所有被read.table处理过的数据执行dplyr的清洗
lapply(function(df) dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT)
) # 有些文件里读出来的数据格式不同，在这里统一所有out文件中的数据格式
) %>%
bind_rows()
# 获取所有的.out文件名
df.mt.out.la <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$") %>%
# 对读取到的所有.out文件x都执行函数read.table
lapply(df.mt.out.la,function(x) read.table(file.path("data/match", x), header = TRUE)) %>%
# 对所有被read.table处理过的数据执行dplyr的清洗
lapply(function(df) dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT)
) # 有些文件里读出来的数据格式不同，在这里统一所有out文件中的数据格式
) %>%
bind_rows()
df.mt.out.la
df.mt.out.la <- df.mt.out.la
df.mt.out.la <- df.mt.out.fl
# 获取所有的.out文件名
df.mt.out.la <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$") %>%
# 对读取到的所有.out文件x都执行函数read.table
lapply(df.mt.out.la,function(x) read.table(file.path("data/match", x), header = TRUE)) %>%
# 对所有被read.table处理过的数据执行dplyr的清洗
lapply(function(df) dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT)
) # 有些文件里读出来的数据格式不同，在这里统一所有out文件中的数据格式
) %>%
bind_rows()
#for loop 或 lapply的都可以
write.csv(df.mt.out.fl, file = "./data/match/match_raw.csv",row.names = FALSE)
#write.csv(df.mt.out.la, file = "./data/match/match_raw.csv",row.names = FALSE)
# 使用select选择age和ALEX的所有题目
df.clean.select <- df.pg.raw %>%
dplyr::select(age, starts_with("ALEX"), eatdrink, avoidance)
# 看看其他变量是不是都消失了
DT::datatable(head(df.clean.select, 10),
fillContainer = TRUE, options = list(pageLength = 3))
# 获取所有的.out文件名
df.mt.out.la <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$") %>%
# 对读取到的所有.out文件x都执行函数read.table
lapply(df.mt.out.la,function(x) read.table(file.path("data/match", x), header = TRUE)) %>%
# 对所有被read.table处理过的数据执行dplyr的清洗
lapply(function(df) dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT)
) # 有些文件里读出来的数据格式不同，在这里统一所有out文件中的数据格式
) %>%
bind_rows()
# 获取所有的.out文件名
df.mt.out.la <- list.files(file.path("data/match"), pattern = "data_exp7_rep_match_.*\\.out$") %>%
# 对读取到的所有.out文件x都执行函数read.table
lapply(.,function(x) read.table(file.path("data/match", x), header = TRUE)) %>%
# 对所有被read.table处理过的数据执行dplyr的清洗
lapply(function(df) dplyr::filter(df, Date != "Date") %>% # 因为有些.out文件中部还有变量名，所需需要用filter把这些行过滤掉
dplyr::mutate(Date = as.character(Date),Prac = as.character(Prac),
Sub = as.numeric(Sub),Age = as.numeric(Age),Sex = as.character(Sex),Hand = as.character(Hand),
Block = as.numeric(Block),Bin = as.numeric(Bin),Trial = as.numeric(Trial),
Shape = as.character(Shape),Label = as.character(Shape),Match = as.character(Match),
CorrResp = as.character(CorrResp),Resp = as.character(Resp),
ACC = as.numeric(ACC),RT = as.numeric(RT)
) # 有些文件里读出来的数据格式不同，在这里统一所有out文件中的数据格式
) %>%
bind_rows()
# 读取原始数据
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
# 使用select选择age和ALEX的所有题目
df.clean.select <- df.pg.raw %>%
dplyr::select(age, starts_with("ALEX"), eatdrink, avoidance)
#笨一点的方法，就是把16个ALEX都写出来
# 把ALEX1 - 4求和
df.clean.mutate_1 <- df.pg.raw %>%
dplyr::mutate(ALEX_SUM = ALEX1 + ALEX2 + ALEX3 + ALEX4)
# 看看其他变量是不是都消失了
DT::datatable(head(df.clean.select, 10),
fillContainer = TRUE, options = list(pageLength = 3))
# 把ALEX1 - 4求和
df.clean.mutate_1 <- df.pg.raw %>%
dplyr::mutate(ALEX_SUM = ALEX1 + ALEX2 + ALEX3 + ALEX4)
# 看看是不是真的求和了
DT::datatable(head(df.clean.mutate_1, 10),
fillContainer = TRUE, options = list(pageLength = 3))
# 对所有含有ALEX的列求和
df.clean.mutate_2 <- df.pg.raw %>%
dplyr::mutate(ALEX_SUM = rowSums(select(., starts_with("ALEX"))))
DT::datatable(head(df.clean.mutate_2, 10),
fillContainer = TRUE, options = list(pageLength = 3))
df.clean.mutate_3 <- df.pg.raw %>%
dplyr::mutate(decade = case_when(age <= 1969 ~ 60,
age >= 1970 & age <= 1979 ~ 70,
age >= 1980 & age <= 1989 ~ 80,
age >= 1990 & age <= 1999 ~ 90,
TRUE ~ NA_real_)
) %>% #当括号多的时候注意括号的位置
dplyr::select(.,decade, everything())
DT::datatable(head(df.clean.mutate_3, 10),
fillContainer = TRUE, options = list(pageLength = 3))
df.clean.group_by <- df.clean.mutate_3 %>%
dplyr::group_by(.,decade) %>% # 根据被试的出生年代，将数据拆分
dplyr::summarise(mean_avoidance = mean(avoidance)) %>% # 计算不同年代下被试的平均avoidance
dplyr::ungroup()
# 拆分文件并不会让源文件产生任何视觉上的变化
DT::datatable(head(df.clean.group_by, 4),
fillContainer = TRUE, options = list(pageLength = 4))
df.pg.clean <- df.pg.raw %>%
dplyr::filter(eatdrink == 1) %>% # 选择eatdrink为1的被试
dplyr::select(age, starts_with("ALEX"), eatdrink, avoidance) %>%
dplyr::mutate(ALEX1 = case_when(ALEX1 == '1' ~ '5', # 反向计分
ALEX1 == '2' ~ '4',
ALEX1 == '3' ~ '3',
ALEX1 == '4' ~ '2',
ALEX1 == '5' ~ '1',
TRUE ~ as.character(ALEX1))) %>%
dplyr::mutate(ALEX1 = as.numeric(ALEX1)) %>%
dplyr::mutate(ALEX_SUM = rowSums(select(., starts_with("ALEX"))), # 把所有ALEX的题目分数求和
decade = case_when(age <= 1969 ~ 60, # 把出生年份转换为年代
age >= 1970 & age <= 1979 ~ 70,
age >= 1980 & age <= 1989 ~ 80,
age >= 1990 & age <= 1999 ~ 90,
TRUE ~ NA_real_)) %>%
dplyr::group_by(decade) %>% # 按照年代将数据拆分
dplyr::summarise(mean_ALEX = mean(ALEX_SUM)) %>% # 计算每个年代的被试的平均的ALEX_SUM
dplyr::ungroup() # 解除对数据的拆分
function1(argument1 = 123,argument2 = "helloworld",argument3 = list1)
library("tidyverse")
group <- df.mt.raw %>%
group_by(Shape)
# 读取原始数据
df.mt.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)
library("tidyverse")
group <- df.mt.raw %>%
group_by(Shape)
group#注意看数据框的第二行，有Groups:   Shape [4]的信息
library("tidyverse")
df.mt.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)
group <- df.mt.raw %>%
group_by(.,Shape) %>%
summarise(n())
DT::datatable(group)
ungroup <- df.mt.raw %>%
summarise(n())
DT::datatable(ungroup)
fun1 <- function(a = 1,b = 100){
sum <- 0
for (i in a:b) {
sum <- sum + i
}
return(sum)
}
fun1 <- function(a = 1,b = 100){#第一个{构成最外层代码块的起始
sum <- 0
for (i in a:b) {#第二个{构成次外层代码块的起始
sum <- sum + i
}#与第二个{对应的}构成次外层代码块的结尾
return(sum)
}#与第一个{对应的}构成最外层代码块的结尾
sum <- 0
#variable i  sequence 1:100
for (i in 1:100) {#statement
sum <- sum + i
}
print(sum)
files <- list.files(file.path("data/match"),
pattern = "data_exp7_rep_match_.*\\.out$")
df_list <- list()
for (i in seq_along(files)) {
df <- read.table(file.path("data/match", files[i]), header = TRUE)
df_list[[i]] <- df
}
df.mt.clean <- df.mt.raw %>%
dplyr::select(Sub, Block, Bin,  # block and bin
Shape, Match, # 自变量
ACC, RT, # 反应结果
) %>%
tidyr::drop_na()
df.mt.clean <- df.mt.raw %>%
dplyr::select(Sub, Block, Bin,  # block and bin
Shape, Match, # 自变量
ACC, RT, # 反应结果
) %>%
tidyr::drop_na()  %>% #删除缺失值
dplyr::group_by(Sub, Block, Bin, Shape)
df.mt.clean <- df.mt.raw %>%
dplyr::select(Sub, Block, Bin,  # block and bin
Shape, Match, # 自变量
ACC, RT, # 反应结果
) %>%
tidyr::drop_na()  %>% #删除缺失值
dplyr::group_by(Sub, Block, Bin, Shape) %>%
dplyr::summarise(
hit = length(ACC[Match == "match" & ACC == 1]),
fa = length(ACC[Match == "mismatch" & ACC == 0]),
miss = length(ACC[Match == "match" & ACC == 0]),
cr = length(ACC[Match == "mismatch" & ACC == 1]),
Dprime = qnorm(
ifelse(hit / (hit + miss) < 1,
hit / (hit + miss),
1 - 1 / (2 * (hit + miss))
)
) - qnorm(
ifelse(fa / (fa + cr) > 0,
fa / (fa + cr),
1 / (2 * (fa + cr))
)
))
df.mt.clean <- df.mt.raw %>%
dplyr::select(Sub, Block, Bin,  # block and bin
Shape, Match, # 自变量
ACC, RT, # 反应结果
) %>%
tidyr::drop_na()  %>% #删除缺失值
dplyr::group_by(Sub, Block, Bin, Shape) %>%
dplyr::summarise(
hit = length(ACC[Match == "match" & ACC == 1]),
fa = length(ACC[Match == "mismatch" & ACC == 0]),
miss = length(ACC[Match == "match" & ACC == 0]),
cr = length(ACC[Match == "mismatch" & ACC == 1]),
Dprime = qnorm(
ifelse(hit / (hit + miss) < 1,
hit / (hit + miss),
1 - 1 / (2 * (hit + miss))
)
) - qnorm(
ifelse(fa / (fa + cr) > 0,
fa / (fa + cr),
1 / (2 * (fa + cr))
)
)) %>%
dplyr::ungroup() %>%
select(-"hit",-"fa",-"miss",-"cr") %>%
dplyr::group_by(Sub, Shape)  %>%
tidyr::pivot_wider(names_from = Shape,
values_from = Dprime)
bookdown::publish_book()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
WD <-  here::here()
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
DT::datatable(head(df.pg.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
df.pg.mean <- df.pg.raw %>%
dplyr::filter(sex > 0 & sex < 3) %>%
dplyr::mutate(ECR_mean = rowMeans(select(., starts_with("ECR")),na.rm = T),
HOME_mean = rowMeans(select(., starts_with("HOME")),na.rm = T),
sex=as.factor(sex)
) %>%
dplyr::select(sex, ECR_mean, HOME_mean, Temperature_t1,Temperature_t2)
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "="
file = "./output/chp7/single_t.doc")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=",
file = "./output/chp7/single_t.doc")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y = c("Temperature_t1",
"Temperature_t2"),
paired = T)  #是否为配对样本t检验？默认是FALSE
})
writeLines(result.ttest, "./output/chp7/pair_t.md")
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
install.packages("bruceR")
library(bruceR)
library(dplyr)
library(tidyr)
WD <-  here::here()
df.pg.raw <-  read.csv('./data/penguin/penguin_rawdata.csv',
header = T, sep=",", stringsAsFactors = FALSE)
df.pg.mean <- df.pg.raw %>%
dplyr::filter(sex > 0 & sex < 3) %>%
dplyr::mutate(ECR_mean = rowMeans(select(., starts_with("ECR")),na.rm = T),
HOME_mean = rowMeans(select(., starts_with("HOME")),na.rm = T),
sex=as.factor(sex)
) %>%
dplyr::select(sex, ECR_mean, HOME_mean, Temperature_t1,Temperature_t2)
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = ">")
bruceR::TTEST(df.pg.mean, "HOME_mean", test.value = 3.5, test.sided = "<")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="HOME_mean",
test.value = 3.5,
test.sided = "=",
file = "./output/chp7/single_t.doc")
})
writeLines(result.ttest, "./output/chp7/single_t.md") # .md最整齐
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y="ECR_mean",
x="sex")
})
writeLines(result.ttest, "./output/chp7/inde_t.md")
result.ttest <- capture.output({
bruceR::TTEST(data=df.pg.mean,
y = c("Temperature_t1",
"Temperature_t2"),
paired = T)  #是否为配对样本t检验？默认是FALSE
})
writeLines(result.ttest, "./output/chp7/pair_t.md")
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
DT::datatable(head(df.match.raw, 10),
fillContainer = TRUE, options = list(pageLength = 5))
#比较被试在匹配任务和不匹配任务上的反应时是否存在差异
#单因素被试内设计（长型数据）
result.anova <- capture.output({
df_within <- df.match.mean%>%
bruceR::MANOVA(subID="Sub",#被试id
dv="rt_mean",#因变量，因为是MANOVA，实际上因变量可以再后面设置很多个
within="Match") #设置条件，因素分析的条件
})
writeLines(result.anova, "./output/chp7/anova_1.md")
# 若不符合球形假设要加上：sph.correction = "GG"
WD <-  here::here()
df.match.raw <-  read.csv('./data/match/match_raw.csv',
header = T, sep=",", stringsAsFactors = FALSE)%>%
tidyr::separate(., col=Shape,into = c("Valence","Identity"),
sep = "(?<=moral|immoral)(?=Self|Other)")%>% #拆分单元格内字符串
dplyr::select(Sub,Valence,Identity,everything())%>%
dplyr::filter(ACC == 1) %>% #只选择回答正确的数据
dplyr::filter(RT > quantile(RT, 0.0015) & RT < quantile(RT, 0.9985)) %>% #remove outliers below and above 3rd sd
dplyr::mutate(RT = as.numeric(RT)) %>%
dplyr::mutate(across("ACC", as.factor)) %>%
dplyr::mutate(Valence = as.factor(Valence)) %>%
dplyr::mutate(Identity = as.factor(Identity)) %>%
dplyr::filter(!is.na(RT)) #剔除缺失值
df.match.mean <- df.match.raw %>%
dplyr::group_by(Sub, Match) %>%
dplyr::summarise(
n = n(),
rt_sd = sd(as.numeric(RT), na.rm = T),
rt_mean = mean(as.numeric(RT), na.rm = T),
acc_mean=mean(as.numeric(as.character(ACC)),na.rm=T)#对于factor数据，先转成character，再变成numeric
) %>%
dplyr::ungroup()
#比较被试在匹配任务和不匹配任务上的反应时是否存在差异
#单因素被试内设计（长型数据）
result.anova <- capture.output({
df_within <- df.match.mean%>%
bruceR::MANOVA(subID="Sub",#被试id
dv="rt_mean",#因变量，因为是MANOVA，实际上因变量可以再后面设置很多个
within="Match") #设置条件，因素分析的条件
})
writeLines(result.anova, "./output/chp7/anova_1.md")
# 若不符合球形假设要加上：sph.correction = "GG"
